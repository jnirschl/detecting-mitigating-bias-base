{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Milestone_2.ipynb","provenance":[],"authorship_tag":"ABX9TyNTWreLiNWd+iU1+MUUWzPN"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"4daGbpPF1zcQ"},"source":["#Mitigate Machine Learning Bias: Shap and AIF360\n","\n","This notebook represents my personal code, notes, and reflections for the Manning liveProject titled \"Mitigate Machine Learning Bias: Shap and AIF360\" by Michael McKenna. "]},{"cell_type":"markdown","metadata":{"id":"h0neTmFY6A2G"},"source":["#### Copyright 2020 Jeff Nirschl"]},{"cell_type":"code","metadata":{"id":"jx2o-Avb6IIm","executionInfo":{"status":"ok","timestamp":1609106213068,"user_tz":480,"elapsed":924,"user":{"displayName":"Jeffrey Nirschl","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZfwR8GXWQBTuk03pMYnD2nBjD0hZXfL7nzmf14Q=s64","userId":"07448025753220635160"}}},"source":["#@title Licensed under the MIT License (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://opensource.org/licenses/MIT\n","#\n","# Copyright 2020 Jeffrey J. Nirschl\n","# \n","# Permission is hereby granted, free of charge, to any person obtaining a copy of \n","# this software and associated documentation files (the \"Software\"), to deal in th\n","# e Software without restriction, including without limitation the rights to use, \n","# copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the \n","# Software, and to permit persons to whom the Software is furnished to do so, subj\n","# ect to the following conditions:\n","# \n","# The above copyright notice and this permission notice shall be included in all c\n","# opies or substantial portions of the Software.\n","# \n","# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLI\n","# ED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR \n","# A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYR\n","# IGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN \n","# ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WIT\n","# H THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4XOepseM4XLQ"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"QWEjAW2a1nyI"},"source":["# Milestone 2\n"]},{"cell_type":"markdown","metadata":{"id":"XKgjgecrGcyX"},"source":["## Performance metrics\n","* **Precision (P)**: $\\frac{TP}{TP + FP}$\n","  * Also known as the *positive predictive value*\n","* **Recall (R)**: $\\frac{TP}{TP + FN}$\n","  * Also known as the *sensitivity* or *true positive rate*\n","* **$F_{1}$ score**:$\\frac{2 \\cdot P R}{P + R}$\n","  *  *Harmonic mean* of precision and recall.\n","* **$F_{\\beta}$ score**: $F_{\\beta}=\\frac{(1+\\beta^{2})PR}{\\beta^{2}PR}$\n","  * Parameterized F1 score to weight precision or recall\n","    * If $\\beta=1:$ Equal weight to precision and recall (e.g.,  $F_{\\beta}=F_{1}$)\n","    * If $\\beta<1:$ More weight to **precision**\n","    * If $\\beta>1:$ More weight to **recall**"]},{"cell_type":"markdown","metadata":{"id":"lDKqLY8vKOnX"},"source":["## Bias metrics\n","### Definitions\n","* **Average odds difference**:\n","* **Equal opportunity difference**\n","* **Disparate impact**: ratio of favorable outcome for the *unpriviledged* group relative to the *priviledged* group. A value of one is no disparate impact whereas values less than one favor the *priviledged* group and values greater than one favor the *unprivileged* group.\n","* **Statistical Parity Difference**:\n","* **Theil Index**:\n","* **Allocation harm**:\n","* **Algorithmic bias**:\n"]},{"cell_type":"markdown","metadata":{"id":"oLppW5jWYcaF"},"source":["## [Google Machine Learning Crash Course: Fairness](https://developers.google.com/machine-learning/crash-course/fairness/types-of-bias)"]},{"cell_type":"markdown","metadata":{"id":"FTD-nGyJPvD8"},"source":["### Human biases\n","\n","#### Human biases *in data*\n","* **Reporting bias**: data is not an accurate reflection of real-world outcomes, events, or frequencies\n","* **Selection bias**: when examples are not a random sample of the intended population. The act of observing an event itself can be a form of selection when a non-random process is correlated with the ability to be observed or measured. Thus, it has been noted that \"observation is selection\" [(Whitehead, 1925)](https://https://archive.org/stream/sciencemodernwor00whit)\n","  * *Coverage bias*: data not selected in a random manner\n","  * *Non-response bias (aka participation bias)*: data is not representative due to systematic differences between participants and non-participants\n","  * *Sampling bias*: proper randomization not used during data collection\n","  * *Survivorship bias*: \n","  * Abraham Wald and [survivorship bias in World War II aircraft](https://clearthinking.co/survivorship-bias/)\n","* **Overgeneralization**\n","* **Out-group homogeneity bias**: tendency to assume people in \"out-groups\" are more similar than our own group \n","* **Systematic or structural biases**\n","  * Biases that exist in the world and are embedded in the data we collect (e.g., racial injustice)\n","\n","#### Human biases in *collection and annotation*\n","* **Confirmation bias**: preferring information or evidence that confirms pre-existing beliefs\n","* **Automation bias**: the tendency to prefer suggestions from automated systems\n","* **Unconscious biases**: other unconscious biase that can extend into our AI \n"]},{"cell_type":"markdown","metadata":{"id":"5dqljvIKYoGt"},"source":["\n","### Designing for fairness\n","1. Consider the problem\n","  * Should the problem or task exist in the first place?\n","  * What is represented in the dataset? What is overlooked?\n","2. Ask experts\n","3. Train the models to account for bias\n","  * What are outliers in the data? How does the algorithm handle outliers?\n","  * What implicit assumptions does the model make about the data or task?\n","4. Interpret outcomes\n","  * Is the ML system over-generalizing?\n","  * How would a human perform the task? \n","5. Publish with *context*\n","  * How should the technology be used?"]},{"cell_type":"markdown","metadata":{"id":"inxX-yPdYryZ"},"source":["### Identifying bias\n","\n","#### Missing features\n","Missing data occurs for a variety of reasons, however it has the potential to introduce bias if the data is missing due to a non-random process. An adequate description of the number of missing values as well as the percent of missing values per class is a first step to check if data are missing due to systematic factors or confounders. \n","\n","Check for missing values in a Pandas DataFrame:\n","```\n","DataFrame.describe()\n","DataFrame.info()\n","```\n","\n","Even if the missing values are at random, we must consider how our learning algorithm handles missing values. Does the algorithm or workflow impute missing values etc.? Additional data exploration may be necessary to rule out other biases that can be introduced by missing features.\n","\n","\\\\\n","#### Unexpected feature values\n","Extreme or unexpected feature values can indicate problems in the data or other inaccuracies that could introduce bias. Understanding the problem domain and characteristics of the data will help reveal errors in the data or unrealistic feature values."]},{"cell_type":"markdown","metadata":{"id":"jC_iEfa83Nn0"},"source":["### [Google Responsible AI Practices](https://ai.google/responsibilities/responsible-ai-practices/)"]},{"cell_type":"code","metadata":{"id":"91Dmt4mA1HCS"},"source":[""],"execution_count":null,"outputs":[]}]}